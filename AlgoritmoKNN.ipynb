{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Práctica Clasificación:  Algoritmo KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importamos todas las librerías que vamos a utilizar inicialmente. Posteriormente iremos importando las librerías específicas de cada apartado de la práctica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load ../../standard_import.txt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from test_helper import Test\n",
    "\n",
    "pd.set_option('display.notebook_repr_html', False)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 150)\n",
    "pd.set_option('display.max_seq_items', None)\n",
    " \n",
    "#%config InlineBackend.figure_formats = {'pdf',}\n",
    "%matplotlib inline  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta práctica vamos a analizar el comportamiento de los árboles de decisión para resolver problemas de clasificación. En concreto, para desarrollar la práctica vamos a trabajar con el dataset Iris (flores de lirio). \n",
    "\n",
    "La librería scikit-learn (sklearn) nos ofrece dicho dataset de forma automática. Para ello hay que importar en primer lugar el paquete datasets y luego utilizar la función load_iris(), que carga el contenido del conjunto de datos Iris en la variable utilizada para tal efecto.\n",
    "\n",
    "La información sobre la función load_iris() se puede encontrar en la URL: http://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_iris.html#sklearn.datasets.load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['setosa', 'versicolor', 'virginica']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Se importa el paquete datasets\n",
    "from sklearn.datasets import load_iris\n",
    "# Se lee el dataset iris y se almacena en la variable del mismo nombre\n",
    "iris =  load_iris()\n",
    "print iris.target[[10, 25, 50]]\n",
    "list(iris.target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la variable iris tenemos los datos asociados a los 150 ejemplos de la base de datos. En concreto:\n",
    "* Los datos de entrada (longitud y anchura de pétalo y de sépalo) están en el campo data (iris.data)\n",
    "* Las salidas (clases) están en el campo target (iris.target)\n",
    "* Los nombres de las clases están en el campo taget_names (iris.target_names)\n",
    "* Los nombres de las variables de entrada están en el campo feature_names (iris.feature_names)\n",
    "* La descripción del dataset está en el campo DESCR (iris.DESCR)\n",
    "\n",
    "Mostrar los datos de todos los campos (los 5 primeros ejemplos) para entender bien el conjunto de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================DATOS IRIS=================\n",
      "[[ 5.1  3.5  1.4  0.2]\n",
      " [ 4.9  3.   1.4  0.2]\n",
      " [ 4.7  3.2  1.3  0.2]\n",
      " [ 4.6  3.1  1.5  0.2]\n",
      " [ 5.   3.6  1.4  0.2]]\n",
      "=================DATOS TARGET=================\n",
      "[0 0 0 0 0]\n",
      "=================DATOS TARGET NAMES=================\n",
      "['setosa' 'versicolor' 'virginica']\n",
      "=================DATOS FEATURE=================\n",
      "['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
      "=================DATOS DESCRIP=================\n",
      "Iris Plants Database\n",
      "\n",
      "Notes\n",
      "-----\n",
      "Data Set Characteristics:\n",
      "    :Number of Instances: 150 (50 in each of three classes)\n",
      "    :Number of Attributes: 4 numeric, predictive attributes and the class\n",
      "    :Attribute Information:\n",
      "        - sepal length in cm\n",
      "        - sepal width in cm\n",
      "        - petal length in cm\n",
      "        - petal width in cm\n",
      "        - class:\n",
      "                - Iris-Setosa\n",
      "                - Iris-Versicolour\n",
      "                - Iris-Virginica\n",
      "    :Summary Statistics:\n",
      "\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "                    Min  Max   Mean    SD   Class Correlation\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "    sepal length:   4.3  7.9   5.84   0.83    0.7826\n",
      "    sepal width:    2.0  4.4   3.05   0.43   -0.4194\n",
      "    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\n",
      "    petal width:    0.1  2.5   1.20  0.76     0.9565  (high!)\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "    :Class Distribution: 33.3% for each of 3 classes.\n",
      "    :Creator: R.A. Fisher\n",
      "    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
      "    :Date: July, 1988\n",
      "\n",
      "This is a copy of UCI ML iris datasets.\n",
      "http://archive.ics.uci.edu/ml/datasets/Iris\n",
      "\n",
      "The famous Iris database, first used by Sir R.A Fisher\n",
      "\n",
      "This is perhaps the best known database to be found in the\n",
      "pattern recognition literature.  Fisher's paper is a classic in the field and\n",
      "is referenced frequently to this day.  (See Duda & Hart, for example.)  The\n",
      "data set contains 3 classes of 50 instances each, where each class refers to a\n",
      "type of iris plant.  One class is linearly separable from the other 2; the\n",
      "latter are NOT linearly separable from each other.\n",
      "\n",
      "References\n",
      "----------\n",
      "   - Fisher,R.A. \"The use of multiple measurements in taxonomic problems\"\n",
      "     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\n",
      "     Mathematical Statistics\" (John Wiley, NY, 1950).\n",
      "   - Duda,R.O., & Hart,P.E. (1973) Pattern Classification and Scene Analysis.\n",
      "     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\n",
      "   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\n",
      "     Structure and Classification Rule for Recognition in Partially Exposed\n",
      "     Environments\".  IEEE Transactions on Pattern Analysis and Machine\n",
      "     Intelligence, Vol. PAMI-2, No. 1, 67-71.\n",
      "   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\n",
      "     on Information Theory, May 1972, 431-433.\n",
      "   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\n",
      "     conceptual clustering system finds 3 classes in the data.\n",
      "   - Many, many more ...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Se imprime la información del dataset 'DATOS IRIS'\n",
    "print '=================DATOS IRIS================='\n",
    "print iris.data[0:5]\n",
    "print '=================DATOS TARGET================='\n",
    "print iris.target[0:5]\n",
    "print '=================DATOS TARGET NAMES================='\n",
    "print iris.target_names\n",
    "print '=================DATOS FEATURE================='\n",
    "print iris.feature_names\n",
    "print '=================DATOS DESCRIP================='\n",
    "print iris.DESCR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algoritmo de los k vecinos más cercanos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La librería Scikit-Learn nos ofrece una implementación del algoritmo de los k vecinos más cercanos que está dentro del paquete neighbors y cuya clase específica es KNeighborsClassifier, cuya información se puede consultar en la siguiente URL: http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier\n",
    "\n",
    "Lo primero que se debe realizar es llamar a la función que crea el modelo de clasificación. Esta función tiene varios parámetros que determinan el comportamiento del algoritmo. La llamada al constructor y sus parámetros son los siguientes:\n",
    "\n",
    "modeloClasificacion = neighbors.KNeighborsClassifier(n_neighbors  = K, weights = tipoVoto, metric = tipoDistancia, p = r)\n",
    "\n",
    "Los diferentes parámetros de entrada son\n",
    "* n_neighbors = K: número de vecinos a considerar (valor por defecto = 5)\n",
    "* weights = tipoVoto: forma de votar (peso de cada ejemplo cercano). tipoVoto puede tomar los siguientes valores:\n",
    "    * 'uniform': voto por mayoría  (valor por defecto)\n",
    "    * 'distance': voto en función de la inversa de la distancia\n",
    "* metric = tipoDistancia: forma de calcular la distancia entre los ejemplos.  tipoDistancia puede tomar los siguientes valores:\n",
    "    * 'manhattan': distancia de manhattan\n",
    "    * 'euclidean': distancia euclidea\n",
    "    * 'minkowski': distancia de Minkowski (valor por defecto)\n",
    "* r: en caso de utilizar la distancia de Minkowski hay que especificar el valor del parámetro p que se corresponde al exponente r visto en la clase de teoría. r puede cualquier valor, entre ellos:\n",
    "    * r = 1: distancia de manhattan\n",
    "    * r = 2: distancia euclidea (valor por defecto)\n",
    "    \n",
    "Crear el modelo inicial con todos los valores por defecto. Almacenar el modelo en una variable llamada clasificador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
      "           weights='uniform')\n"
     ]
    }
   ],
   "source": [
    "# Importamos la librería neighbors\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# Llamamos al constructor de KNN\n",
    "clasificador = KNeighborsClassifier(n_neighbors=5)\n",
    "#clasificador = KNeighborsClassifier(n_neighbors=7, weights='uniform', metric='manhattan')\n",
    "print clasificador"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez creado el modelo debemos entrenarlo. Para ello se debe llamar al método fit del objeto creado anteriormente. A dicho método se le deben pasar los datos de entrenamiento (en este caso todos los datos) tanto de las variables de entrada como de la salida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
      "           weights='uniform')\n"
     ]
    }
   ],
   "source": [
    "# Entrenamos KNN\n",
    "clasificador.fit(iris.data, iris.target)\n",
    "print clasificador"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez que el modelo está entrenado lo podemos utilizar para realizar predicciones de nuevos datos. Para ello se debe llamar al método predict al que se pasa como parámetro de entrada los ejemplos a predecir (en este caso vamos a predecir la clase de todos los ejemplos). Guardar el resultado de las clases predichas en una variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 2 1\n",
      " 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 1 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n",
      "[0]\n",
      "[2]\n"
     ]
    }
   ],
   "source": [
    "# Realizamos las predicciones para los píxeles de entrenamiento\n",
    "predicciones = (clasificador.predict(iris.data))\n",
    "#KNeighborsClassifier(metric='euclidean', shrink_threshold=None)\n",
    "\n",
    "print predicciones\n",
    "print (clasificador.predict([[4.3,2.0,1,0.1]]))\n",
    "print (clasificador.predict([[7.9,4.4,6.9,2.5]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este punto ya tenemos las predicciones de todos los píxeles de entrenamiento por lo que podemos calcular el rendimiento del modelo. \n",
    "\n",
    "Scikit-learn también nos ofrece una función que nos permite calcular de forma automática el accuracy de un modelo de clasificación. Esta función está dentro de la librería metrics y por tanto hay que importarla para poder utilizarla.\n",
    "\n",
    "    from sklean import metrics\n",
    "    \n",
    "La función se llama accuracy_score y su información se puede consultar en la URL: . \n",
    "\n",
    "    acc = metrics.accuracy_score(clasesReales, clasesPredichas)\n",
    "\n",
    "Esta función recibe dos parámetros de entrada:\n",
    "* clasesReales: vector con las clases reales de los ejemplos predichos.\n",
    "* clasesPredichas: vector con las clases predichas por el modelo para los ejemplos.\n",
    "La función devuelve un valor real que representa el accuracy del sistema. Este valor está entre 0 y 1 por lo que si queremos obtener el accuracy entre 0 y 100 hay que multiplicar el valor devuelto por 100.0.\n",
    "\n",
    "Ejercicio: obtén el accuracy anterior utilizando la función accuracy_score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96.67\n",
      "1 test passed.\n"
     ]
    }
   ],
   "source": [
    "# Importamos la librería metrics\n",
    "from sklearn import metrics\n",
    "# Calculamos el porcentaje de acierto\n",
    "acc = metrics.accuracy_score(iris.target, predicciones)*100.0\n",
    "print round(acc,2)\n",
    "\n",
    "Test.assertEquals(round(acc, 2), 96.67, 'Porcentaje de acierto incorrecto')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También podéis mostrar la matriz de confusión para observar en qué clases se confunde más el clasificador. Utilizar la función confusion_matrix de la librería metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[50,  0,  0],\n",
       "       [ 0, 47,  3],\n",
       "       [ 0,  2, 48]])"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "# Mostramos la matriz de confusión\n",
    "#confusion_matrix(iris.target, predicciones, labels=[0,1,2])\n",
    "confusion_matrix(iris.target, predicciones)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por último, vamos a visualizar la frontera de decisión que genera el clasificador KNN. Debéis hacer lo siguiente:\n",
    "* Crear una matriz X con todos los datos de entrada de Iris pero solamente con las dos últimas variables (recordar utilizar copy).\n",
    "* Crear una matriz y con todos los datos de salida de Iris.\n",
    "* Normalizar los valores de X utilizando el método del mínimo y el máximo.\n",
    "* Aprender el clasificador con los datos normalizados utilizando 3 vecinos, y la distancia de Manhattan. (A realizar)\n",
    "* Se crea una nube de puntos con todas las combinaciones entre el mínimo (-0.1) y el máximo (+0.1) con incrementos de 0.02 de las dos variables.\n",
    "* Se realiza la predicción de todos los ejemplos generados.\n",
    "* Se crea la gráfica donde la predicción de cada clase sale en dieferentes colores (contour) y se muestran los ejemplos de entrenamiento (scatter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-154-4069c31fd888>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-154-4069c31fd888>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    print X = iris.data[:, 0]\u001b[0m\n\u001b[0m            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "#Xnorm = \n",
    "\n",
    "# Creación del modelo\n",
    "modeloClas = #<RELLENAR>\n",
    "# Entrenamiento del modelo\n",
    "modeloClas = #<RELLENAR>\n",
    "\n",
    "#se crea una gráfica para mostrar la superficie de decisión del clasificador aprendido\n",
    "h = .02  # tamaño de avance en el mesh\n",
    "#TAREA: calcula el mínimo (menos 1) y el máximo (más 1) de las variables x e y\n",
    "x_min = Xnorm[:, 0].min() - 0.1\n",
    "x_max = Xnorm[:, 0].max() + 0.1\n",
    "y_min = Xnorm[:, 1].min() - 0.1\n",
    "y_max = Xnorm[:, 1].max() + 0.1\n",
    "\n",
    "# Se crean todas las combinaciones de valores\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "# Se predicen todos los puntos de la superficio de la gráfica con el clasificador aprendido\n",
    "Z = modeloClas.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "#Se muestran los resultados en la gráfica: la función contourf colorea toda la superficie\n",
    "Z = Z.reshape(xx.shape)\n",
    "plt.figure(1)\n",
    "plt.contourf(xx, yy, Z, cmap=plt.cm.Paired)\n",
    "\n",
    "#Se muestran los datos del problema: la funcion scatter muestra puntos aislados y los colorea en función de su valor\n",
    "plt.scatter(Xnorm[:, 0], Xnorm[:, 1], c=y, cmap=plt.cm.Paired)\n",
    "#se muestra la figura\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, vamos analizar el efecto de los parámetros del algoritmo KNN:\n",
    "* Número de vecinos (parámetro n_neighbors)\n",
    "    * Probar los resultados con 1, 3, 5 y 7 vecinos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Hacemos una lista para almacenar el porcentaje de acierto de la zona de train con cada valor de k\n",
    "#<RELLENAR>\n",
    "# Por cada valor de k\n",
    "for k in #<RELLENAR>\n",
    "    # Creamos el clasificador con los parámetros apropiados\n",
    "    clasificador = #<RELLENAR>\n",
    "    # Lo entrenamos\n",
    "    clasificador = #<RELLENAR>\n",
    "    # Predecimos las clases de los ejemplos de train\n",
    "    predicciones = #<RELLENAR>\n",
    "    # Calculamos el porcentaje de acierto\n",
    "    acc = #<RELLENAR>\n",
    "    # Lo añadimos a la lista\n",
    "    #<RELLENAR>\n",
    "    # Mostramos los resultados\n",
    "    print(\"Valor de k: {} y su precision es: {}\".format(k,acc))\n",
    "\n",
    "Test.assertEquals(map(lambda ind: round(ind, 2), list(accTrain)), [100.00,96.00,96.67,97.33], 'Accuracies incorrectos')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizando un número de vecinos igual a 3, vamos a analizar el efecto de la forma de votación.\n",
    "* Tipo de voto (parámetro weights)\n",
    "    * Probar los valores 'uniform', 'distance'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Hacemos una lista para almacenar el porcentaje de acierto de la zona de train con cada valor de k\n",
    "#<RELLENAR>\n",
    "# Por cada tipo de voto\n",
    "#<RELLENAR>\n",
    "    # Creamos el clasificador con los parámetros apropiados\n",
    "    clasificador = #<RELLENAR>\n",
    "    # Lo entrenamos\n",
    "    clasificador = #<RELLENAR>\n",
    "    # Predecimos las clases de los ejemplos de train\n",
    "    predicciones = #<RELLENAR>\n",
    "    # Calculamos el porcentaje de acierto\n",
    "    acc = #<RELLENAR>\n",
    "    # Lo añadimos a la lista\n",
    "    #<RELLENAR>\n",
    "    # Mostramos los resultados\n",
    "    print(\"Tipo de voto: {} y su precision es: {}\".format(tipoVoto,acc))\n",
    " \n",
    "\n",
    "Test.assertEquals(map(lambda ind: round(ind, 2), accTrain), [96.00,100.00], 'Accuracies incorrectos')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizando un número de vecinos igual a 3, vamos a analizar el efecto de la forma de calcular la distancia.\n",
    "* Tipo de distancia (parámetro metric)\n",
    "    * Probar los valores 'manhattan', 'euclidean'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Hacemos una lista para almacenar el porcentaje de acierto de la zona de train con cada valor de k\n",
    "#<RELLENAR>\n",
    "# Por cada tipo de distancia\n",
    "#<RELLENAR>\n",
    "    # Creamos el clasificador con los parámetros apropiados\n",
    "    clasificador = #<RELLENAR>\n",
    "    # Lo entrenamos\n",
    "    clasificador = #<RELLENAR>\n",
    "    # Predecimos las clases de los ejemplos de train\n",
    "    predicciones = #<RELLENAR>\n",
    "    # Calculamos el porcentaje de acierto\n",
    "    acc = #<RELLENAR>\n",
    "    # Lo añadimos a la lista\n",
    "    #<RELLENAR>\n",
    "    # Mostramos los resultados\n",
    "    print(\"Tipo de distancia: {} y su precision es: {}\".format(tipoDistancia,acc))\n",
    "\n",
    "Test.assertEquals(map(lambda ind: round(ind, 2), accTrain), [96.00,96.00], 'Accuracies incorrectos')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
